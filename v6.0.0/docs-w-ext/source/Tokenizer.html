<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>The source code</title>
  <link href="../resources/prettify/prettify.css" type="text/css" rel="stylesheet" />
  <script type="text/javascript" src="../resources/prettify/prettify.js"></script>
  <style type="text/css">
    .highlight { display: block; background-color: #ddd; }
  </style>
  <script type="text/javascript">
    function highlight() {
      document.getElementById(location.hash.replace(/#/, "")).className = "highlight";
    }
  </script>
</head>
<body onload="prettyPrint(); highlight();">
  <pre class="prettyprint lang-js"><span id='Ext-parse-Tokenizer'>/**
</span> * This class is used to parse a string into a series of tokens. The syntax of the string
 * is JavaScript-like. This class is useful for creating higher-level parsers to allow
 * them to assemble tokens into a meaningful language (such as bind properties).
 *
 * The following set of punctuation characters are supported:
 *
 *      + - * / ! , : [ ] { } ( )
 *
 * This class does not currently separate the dot operator but instead includes it in a
 * single &quot;ident&quot; token. Whitespace between tokens is skipped.
 *
 * Tokens are parsed on-demand when `next` or `peek` are called. As much as possible,
 * the returned tokens are reused (e.g., to represent tokens like &quot;:&quot; the same object is
 * always returned). For tokens that contain values, a new object must be created to
 * return the value. Even so, the `is` property that describes the data is a reused object
 * in all cases.
 *
 *      var tokenizer;  // see below for getting instance
 *
 *      for (;;) {
 *          if (!(token = tokenizer.next())) {
 *              // When null is returned, there are no more tokens
 *
 *              break;
 *          }
 *
 *          var is = token.is;  // the token&#39;s classification object
 *
 *          if (is.error) {
 *              // Once an error is encountered, it will always be returned by
 *              // peek or next. The error is cleared by calling reset().
 *
 *              console.log(&#39;Syntax error&#39;, token.message);
 *              break;
 *          }
 *
 *          if (is.ident) {
 *              // an identifier...
 *              // use token.value to access the name or dot-path
 *
 *              var t = tokenizer.peek();  // don&#39;t consume next token (yet)
 *
 *              if (t &amp;&amp; t.is.parenOpen) {
 *                  tokenizer.next();  // we&#39;ll take this one
 *
 *                  parseThingsInParens();
 *
 *                  t = tokenizer.next();
 *
 *                  mustBeCloseParen(t);
 *              }
 *          }
 *          else if (is.literal) {
 *              // a literal value (null, true/false, string, number)
 *              // use token.value to access the value
 *          }
 *          else if (is.at) {
 *              // @
 *          }
 *      }
 *
 * For details on the returned token see the `peek` method.
 *
 * There is a pool of flyweight instances to reduce memory allocation.
 *
 *      var tokenizer = Ext.parse.Tokenizer.fly(&#39;some.thing:foo()&#39;);
 *
 *      // use tokenizer (see above)
 *
 *      tokenizer.release();  // returns the fly to the flyweigt pool
 *
 * The `release` method returns the flyweight to the pool for later reuse. Failure to call
 * `release` will leave the flyweight empty which simply forces the `fly` method to always
 * create new instances on each call.
 *
 * A tokenizer can also be reused by calling its `reset` method and giving it new text to
 * tokenize.
 *
 *      this.tokenizer = new Ext.parse.Tokenizer();
 *
 *      // Later...
 *
 *      this.tokenizer.reset(&#39;some.thing:foo()&#39;);
 *
 *      // use tokenizer (see above)
 *
 *      this.tokenizer.reset();
 *
 * The final call to `reset` is optional but will avoid holding large text strings or
 * parsed results that rae no longer needed.
 *
 * @private
 */
Ext.define(&#39;Ext.parse.Tokenizer&#39;, function (Tokenizer) {
    var flyweights = (Tokenizer.flyweights = []),
        BOOLEAN = { literal: true, boolean: true },
        ERROR = { error: true },
        IDENT = { ident: true },
        LITERAL = { literal: true },
        NULL = { literal: true, nil: true },
        NUMBER = { literal: true, number: true },
        STRING = { literal: true, string: true };

return {
    extend: &#39;Ext.util.Fly&#39;,

    isTokenizer: true,

    statics: {
        BOOLEAN: BOOLEAN,
        ERROR: ERROR,
        IDENT: IDENT,
        LITERAL: LITERAL,
        NULL: NULL,
        NUMBER: NUMBER,
        STRING: STRING
    },

    config: {
<span id='Ext-parse-Tokenizer-cfg-keywords'>        /**
</span>         * @cfg {Object} keywords
         * A map of keywords that should be mapped to other token types. By default the
         * `null`, `true` and `false` keywords are mapped to their respective literal
         * value tokens.
         */
        keywords: {
            &#39;null&#39;:  { type: &#39;literal&#39;, is: NULL,    value: null },
            &#39;false&#39;: { type: &#39;literal&#39;, is: BOOLEAN, value: false },
            &#39;true&#39;:  { type: &#39;literal&#39;, is: BOOLEAN, value: true }
        },

<span id='Ext-parse-Tokenizer-cfg-operators'>        /**
</span>         * @cfg {Object} operators
         * A map of operators and their names. The keys are the operator text and the
         * name (the values) are placed in the token&#39;s `is` object as `true`.
         */
        operators: {
            &#39;+&#39;: &#39;plus&#39;,
            &#39;-&#39;: &#39;minus&#39;,
            &#39;*&#39;: &#39;multiply&#39;,
            &#39;/&#39;: &#39;divide&#39;,
            &#39;!&#39;: &#39;bang&#39;,
            &#39;,&#39;: &#39;comma&#39;,
            &#39;:&#39;: &#39;colon&#39;,
            &#39;[&#39;: &#39;arrayOpen&#39;,
            &#39;]&#39;: &#39;arrayClose&#39;,
            &#39;{&#39;: &#39;curlyOpen&#39;,
            &#39;}&#39;: &#39;curlyClose&#39;,
            &#39;(&#39;: &#39;parenOpen&#39;,
            &#39;)&#39;: &#39;parenClose&#39;
        }
    },

<span id='Ext-parse-Tokenizer-property-error'>    /**
</span>     * This property is set to an `Error` instance if the parser encounters a syntax
     * error.
     * @property {Object} error
     * @readonly
     */
    error: null,

<span id='Ext-parse-Tokenizer-property-index'>    /**
</span>     * This property is set to the character index of the current token. This value can
     * be captured immediately after calling the `peek` or `next` method to know the
     * index of the returned token. This value is not included in the returned token to
     * allow those tokens that could otherwise be immutable to be reused.
     * @property {Number} index
     * @readonly
     */
    index: -1,

    constructor: function (config) {
        this.operators = {};

        this.initConfig(config);
    },

<span id='Ext-parse-Tokenizer-method-next'>    /**
</span>     * Advance the token stream and return the next token. See `{@link #peek}` for a
     * description of the returned token.
     *
     * After calling this method, the next call to it or `peek` will not return the same
     * token but instead the token that follows the one returned.
     *
     * @return {Object} The next token in the stream (now consumed).
     */
    next: function () {
        var token = this.peek();

        this.head = undefined;  // indicates that more parsing is needed (see peek)

        return token;
    },

<span id='Ext-parse-Tokenizer-method-peek'>    /**
</span>     * Peeks at the next token stream and returns it. The token remains as the next token
     * and will be returned again by the next call to this method or `next`.
     *
     * At the end of the token stream, the token returned will be `null`.
     *
     * If a syntax error is encountered, the returned token will be an `Error` object. It
     * has the standard `message` property and also additional properties to make it more
     * like a standard token: `error: true`, `type: &#39;error&#39;` and `at` (the index in the
     * string where the syntax error started.
     *
     * @return {Object} The next token in the stream (not yet consumed).
     *
     * @return {String} return.type The type of the token. This will be one of the
     * following values: `ident`, `literal` and `error` or the text of a operator
     * (i.e., &quot;@&quot;, &quot;!&quot;, &quot;,&quot;, &quot;:&quot;, &quot;[&quot;, &quot;]&quot;, &quot;{&quot;, &quot;}&quot;, &quot;(&quot; or &quot;)&quot;).
     *
     * @return {String} return.value The value of a `&quot;literal&quot;` token.
     *
     * @return {Object} return.is An object containing boolean properties based on type.
     * @return {Boolean} return.is.literal True if the token is a literal value.
     * @return {Boolean} return.is.boolean True if the token is a literal boolean value.
     * @return {Boolean} return.is.error True if the token is an error.
     * @return {Boolean} return.is.ident True if the token is an identifier.
     * @return {Boolean} return.is.nil True if the token is the `null` keyword.
     * @return {Boolean} return.is.number True if the token is a number literal.
     * @return {Boolean} return.is.string True if the token is a string literal.
     * @return {Boolean} return.is.operator True if the token is a operator (i.e.,
     * &quot;@!,:[]{}()&quot;). operators will also have one of these boolean proprieties, in
     * the respective order: `at`, `bang`, `comma`, `colon`, `arrayOpen`, `arrayClose`,
     * `curlyOpen`, `curlyClose`, `parentOpen` and `parenClose`).
     */
    peek: function () {
        var me = this,
            error = me.error,
            token = me.head;

        if (error) {
            return error;
        }

        if (token === undefined) {
            me.head = token = me.advance();
        }

        return token;
    },

<span id='Ext-parse-Tokenizer-method-release'>    /**
</span>     * Returns this flyweight instance to the flyweight pool for reuse.
     */
    release: function () {
        this.reset();

        if (flyweights.length &lt; Tokenizer.flyPoolSize) {
            flyweights.push(this);
        }
    },

<span id='Ext-parse-Tokenizer-method-reset'>    /**
</span>     * Resets the tokenizer for a new string at a given offset (defaults to 0).
     *
     * @param {String} text The text to tokenize.
     * @param {Number} [pos=0] The character position at which to start.
     * @param {Number} [end] The index of the first character beyond the token range.
     * @returns {Ext.parse.Tokenizer}
     */
    reset: function (text, pos, end) {
        var me = this;

        me.error = null;
        me.head = undefined;
        me.index = -1;
        me.text = text || null;
        me.pos = pos || 0;
        me.end = (text &amp;&amp; end == null) ? text.length : end;

        return me;
    },

    privates: {
        digitRe: /[0-9]/,
        identFirstRe: /[a-z_$]/i,
        identRe: /[0-9a-z_$]/i,
        spaceRe: /[ \t]/,

<span id='Ext-parse-Tokenizer-property-end'>        /**
</span>         * The index one beyond the last character of the input text. This defaults to
         * the `text.length`.
         * @property {Number} end
         * @readonly
         */
        end: 0,

<span id='Ext-parse-Tokenizer-property-head'>        /**
</span>         * The current token at the head of the token stream. This will be `undefined`
         * if the next token must be parsed from `text`. It is `null` if there are no
         * more tokens.
         * @property {Object} head
         * @readonly
         */
        head: undefined,

<span id='Ext-parse-Tokenizer-property-pos'>        /**
</span>         * The current character position in the `text` from which the next token will
         * be parsed.
         * @property {Number} pos
         * @readonly
         */
        pos: 0,

<span id='Ext-parse-Tokenizer-property-text'>        /**
</span>         * The text to be tokenized.
         * @property {String} text
         * @readonly
         */
        text: null,

        applyOperators: function (ops) {
            var operators = this.operators,
                block, c, def, i, len, name, op;

            /*
             Builds a map one character at a time (i.e., a &quot;trie&quot;):

                operators: {
                    &#39;=&#39;: {
                        &#39;=&#39;: {
                            token: // the &quot;==&quot; token
                        },

                        token:  // the &quot;=&quot; token
                    }
                }
             */
            for (op in ops) {
                block = operators;
                name = ops[op];
                len = op.length;

                for (i = 0; i &lt; len; ++i) {
                    c = op.charAt(i);
                    block = block[c] || (block[c] = {});
                }

                if (name) {
                    block.token = def = {
                        type: &#39;operator&#39;,
                        value: op,
                        is: { operator: true }
                    };

                    def.is[name] = true;
                } else {
                    block.token = null;
                }
            }
        },

<span id='Ext-parse-Tokenizer-method-advance'>        /**
</span>         * Parses and returns the next token from `text` starting at `pos`.
         * @return {Object} The next token
         */
        advance: function () {
            var me = this,
                spaceRe = me.spaceRe,
                text = me.text,
                length = me.end,
                c;

            while (me.pos &lt; length) {
                c = text.charAt(me.pos);

                if (spaceRe.test(c)) {
                    ++me.pos;  // consume the whitespace
                    continue;
                }

                me.index = me.pos;
                return me.parse(c);
            }

            return null;
        },

<span id='Ext-parse-Tokenizer-method-parse'>        /**
</span>         * Parses the current token that starts with the provided character `c` and
         * located at the current `pos` in the `text`.
         * @param {String} c The current character.
         * @return {Object} The next token
         */
        parse: function (c) {
            var me = this,
                digitRe = me.digitRe,
                text = me.text,
                length = me.end,
                ret;

            // Handle &quot;.123&quot;
            if ( c === &#39;.&#39; &amp;&amp; me.pos+1 &lt; length) {
                if (digitRe.test(text.charAt(me.pos+1))) {
                    ret = me.parseNumber();
                }
            }

            if (!ret &amp;&amp; me.operators[c]) {
                ret = me.parseOperator(c);
            }

            if (!ret) {
                if (c === &#39;&quot;&#39; || c === &quot;&#39;&quot;) {
                    ret = me.parseString();
                }
                else if (digitRe.test(c)) {
                    ret = me.parseNumber();
                }
                else if (me.identFirstRe.test(c)) {
                    ret = me.parseIdent();
                }
                else {
                    ret = me.syntaxError(&#39;Unexpected character&#39;);
                }
            }

            return ret;
        },

<span id='Ext-parse-Tokenizer-method-parseIdent'>        /**
</span>         * Parses the next identifier token.
         * @return {Object} The next token.
         */
        parseIdent: function () {
            var me = this,
                identRe = me.identRe,
                keywords = me.getKeywords(),
                includeDots = !me.operators[&#39;.&#39;],
                text = me.text,
                start = me.pos,
                end = start,
                length = me.end,
                prev = 0,
                c, value;

            while (end &lt; length) {
                c = text.charAt(end);

                if (includeDots &amp;&amp; c === &#39;.&#39;) {
                    if (prev === &#39;.&#39;) {
                        return me.syntaxError(end, &#39;Unexpected dot operator&#39;);
                    }
                    ++end;
                }
                else if (identRe.test(c)) {
                    ++end;
                }
                else {
                    break;
                }

                prev = c;
            }

            if (prev === &#39;.&#39;) {
                return me.syntaxError(end - 1, &#39;Unexpected dot operator&#39;);
            }

            value = text.substring(start, me.pos = end);

            return (keywords &amp;&amp; keywords[value]) || {
                type: &#39;ident&#39;,
                is: IDENT,
                value: value
            };
        },

<span id='Ext-parse-Tokenizer-method-parseNumber'>        /**
</span>         * Parses the next number literal token.
         * @return {Object} The next token.
         */
        parseNumber: function () {
            var me = this,
                digitRe = me.digitRe,
                text = me.text,
                start = me.pos,
                length = me.end,
                c, decimal, exp, token;

            while (me.pos &lt; length) {
                c = text.charAt(me.pos);

                if (c === &#39;-&#39; || c === &#39;+&#39;) {
                    if (me.pos !== start) {
                        return me.syntaxError(start, &#39;Invalid number&#39;);
                    }
                    ++me.pos;
                }
                else if (c === &#39;.&#39;) {
                    if (decimal) {
                        break;
                    }
                    decimal = true;
                    ++me.pos;
                }
                else if (c === &#39;e&#39; || c === &#39;E&#39;) {
                    if (exp) {
                        break;
                    }

                    decimal = exp = true; // exp from here on, no decimal allowed

                    c = text.charAt(++me.pos); // consume E and peek ahead

                    if (c === &#39;-&#39; || c === &#39;+&#39;) {
                        ++me.pos;  // keep the exp sign
                    }
                }
                else if (digitRe.test(c)) {
                    ++me.pos;
                }
                else {
                    break;
                }
            }

            token = {
                type: &#39;literal&#39;,
                is: NUMBER,
                // Beware parseFloat as it will stop parsing and return what it could
                // parse. For example parseFloat(&#39;1x&#39;) == 1 whereas +&#39;1x&#39; == NaN.
                value: +text.substring(start, me.pos)
            };

            if (!isFinite(token.value)) {
                token = me.syntaxError(start, &#39;Invalid number&#39;);
            }

            return token;
        },

        parseOperator: function (c) {
            var me = this,
                block = me.operators,
                text = me.text,
                length = me.end,
                end = me.pos,
                match, matchEnd, token;

            while (block[c]) {
                block = block[c];
                token = block.token;
                ++end;

                if (token) {
                    match = token;
                    matchEnd = end;
                }

                if (end &lt; length) {
                    c = text.charAt(end);
                } else {
                    break;
                }
            }

            if (match) {
                me.pos = matchEnd;
            }

            return match;
        },

<span id='Ext-parse-Tokenizer-method-parseString'>        /**
</span>         * Parses the next string literal token.
         * @return {Object} The next token.
         */
        parseString: function () {
            var me = this,
                text = me.text,
                pos = me.pos,
                start = pos,
                length = me.end,
                str = &#39;&#39;,
                c, closed, quote;

            quote = text.charAt(pos++);

            while (pos &lt; length) {
                c = text.charAt(pos++);

                if (c === quote) {
                    closed = true;
                    break;
                }
                if (c === &#39;\\&#39; &amp;&amp; pos &lt; length) {
                    c = text.charAt(pos++);
                }

                // Processing escapes means we cannot use substring() to pick up the
                // text as a single chunk...
                str += c;
            }
            
            me.pos = pos;
            
            if (!closed) {
                return me.syntaxError(start, &#39;Unterminated string&#39;);
            }

            return {
                type: &#39;literal&#39;,
                is: STRING,
                value: str
            };
        },

<span id='Ext-parse-Tokenizer-method-syntaxError'>        /**
</span>         * This method is called when a syntax error is encountered. It updates `error`
         * and returns the error token.
         * @param {Number} at The index of the syntax error (optional).
         * @param {String} message The error message.
         * @return {Object} The error token.
         */
        syntaxError: function (at, message) {
            if (typeof at === &#39;string&#39;) {
                message = at;
                at = this.pos;
            }

            var suffix = (at == null) ? &#39;&#39; : (&#39; (at index &#39; + at + &#39;)&#39;),
                error = new Error(message + suffix);

            error.type = &#39;error&#39;;
            error.is = ERROR;

            if (suffix) {
                error.at = at;
            }

            return this.error = error;
        }
    }
}});
</pre>
</body>
</html>
